{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading and read data\n",
    "\n",
    "First, download the data from [Kaggle](https://www.kaggle.com/datasets/tirendazacademy/fifa-world-cup-2022-tweets/) to the path \"../data/fifa-tweet-sentiments\". Then, extract the .csv in that same directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date Created</th>\n",
       "      <th>Number of Likes</th>\n",
       "      <th>Source of Tweet</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2022-11-20 23:59:21+00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>What are we drinking today @TucanTribe \\n@MadB...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2022-11-20 23:59:01+00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Amazing @CanadaSoccerEN  #WorldCup2022 launch ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2022-11-20 23:58:41+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Worth reading while watching #WorldCup2022 htt...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2022-11-20 23:58:33+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>Golden Maknae shinning bright\\n\\nhttps://t.co/...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2022-11-20 23:58:28+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>If the BBC cares so much about human rights, h...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               Date Created  Number of Likes  \\\n",
       "0           0  2022-11-20 23:59:21+00:00                4   \n",
       "1           1  2022-11-20 23:59:01+00:00                3   \n",
       "2           2  2022-11-20 23:58:41+00:00                1   \n",
       "3           3  2022-11-20 23:58:33+00:00                1   \n",
       "4           4  2022-11-20 23:58:28+00:00                0   \n",
       "\n",
       "       Source of Tweet                                              Tweet  \\\n",
       "0      Twitter Web App  What are we drinking today @TucanTribe \\n@MadB...   \n",
       "1   Twitter for iPhone  Amazing @CanadaSoccerEN  #WorldCup2022 launch ...   \n",
       "2   Twitter for iPhone  Worth reading while watching #WorldCup2022 htt...   \n",
       "3      Twitter Web App  Golden Maknae shinning bright\\n\\nhttps://t.co/...   \n",
       "4  Twitter for Android  If the BBC cares so much about human rights, h...   \n",
       "\n",
       "  Sentiment  \n",
       "0   neutral  \n",
       "1  positive  \n",
       "2  positive  \n",
       "3  positive  \n",
       "4  negative  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = \"../data/fifa-tweet-sentiments/fifa_world_cup_2022_tweets.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make train/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "pre_df = pd.DataFrame({'text': df['Tweet'], 'label': df['Sentiment'].apply(lambda x: sentiment_map[x])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15766, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_split, test_split = train_test_split(pre_df, train_size=0.7)\n",
    "train_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning a pretrained huggingface sentiment classifier\n",
    "\n",
    "Most of the following is adapted from section 3.a of \"[Getting Started with Sentiment Analysis using Python](https://huggingface.co/blog/sentiment-analysis-python).\" This workflow loads a pre-trained DistilBERT model and finetunes a classifier head on top of it. We take this approach to classify tweets from the FIFA dataset above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get pretrained tokenizer and collator to transform input and pad input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    load_accuracy = load_metric(\"accuracy\")\n",
    "\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
    "    return{\"accuracy\": accuracy}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authenticate the notebook so we can write to our repo. Make sure to use a token with `write` privileges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6babd31e20794aea8885cb33797918ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login() # login with a write token here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a pretrained model. Note that we use 3 labels since our data has three possible sentiments (`negative`, `neutral`, `positive`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map the string values for sentiment values to ints, and make a Dataset-compatible dataframe for the huggingface trainer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the DatasetDict object for training/eval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict(train_split)\n",
    "test_dataset = datasets.Dataset.from_dict(test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa099dd0120492ba9b4ffc4a6e4dd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/15766 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16824b4a94a949c39a17afc8768dc522",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6758 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess, batched=True)\n",
    "tokenized_test = test_dataset.map(preprocess, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "repo_name = f\"finetuning-sentiment-model-fifa-{train_split.shape[0]}-samples\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=repo_name,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=1e-2,\n",
    "    save_strategy=\"epoch\",\n",
    "    push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model on the eval set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='423' max='423' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [423/423 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.711454451084137,\n",
       " 'eval_accuracy': 0.8393015685113939,\n",
       " 'eval_runtime': 7.1526,\n",
       " 'eval_samples_per_second': 944.835,\n",
       " 'eval_steps_per_second': 59.14,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Push the model to the remote repo, and evaluate the trained model on some unseen tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7670fed1634b08a23a1c82a41799ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/769 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9c4a9d82a644e0a3e7daa8653ee0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e85e97e040545b3a386110f92e1619a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23949827e6ee4aff92643db50c241816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb043cc542fb44acb3bf8c40442659b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3f2a5f9cc64ae897724df05a8fa344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive with score=0.99932 (\"This team is the greatest!\")\n",
      "negative with score=0.99918 (\"I can't with this team...\")\n",
      "negative with score=0.99802 (\"This game is a snoozefest\")\n",
      "neutral with score=0.99411 (\"What is soccer?\")\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "back_map = {val: key for key, val in sentiment_map.items()}\n",
    "huggingface_username = \"<YOUR_HUGGINGFACE_USERNAME>\"\n",
    "\n",
    "sentiment_model = pipeline(model=f\"{huggingface_username}/finetuning-sentiment-model-fifa-{train_split.shape[0]}-samples\")\n",
    "examples = [\"This team is the greatest!\", \"I can't with this team...\", \"This game is a snoozefest\", \"What is soccer?\"]\n",
    "preds = sentiment_model(examples)\n",
    "for i, pred in enumerate(preds):\n",
    "    print(f'{back_map[int(pred[\"label\"][-1])]} with score={pred[\"score\"]:6.5f} (\"{examples[i]}\")')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment classification using GPT-3.5\n",
    "\n",
    "How well can a finetuned GPT-3.5 do sentiment classification on this dataset? To answer this, we'll finetune the model on a few prompt/completions pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a few helper methods to help us train (finetune) and evaluate the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def makeFinetuneData(split, path, N, n_batch, bs):\n",
    "    with open(path, 'w') as outfile:\n",
    "        for i in range(n_batch):\n",
    "            messages = messagesFromSplit(split, i*bs, (i+1)*bs)\n",
    "\n",
    "            json.dump({'messages': messages}, outfile)\n",
    "            outfile.write('\\n')\n",
    "\n",
    "def messagesFromSplit(split, i_s, i_e, include_assistant=True):\n",
    "    # format the system/user/assistant content\n",
    "\n",
    "    messages = []\n",
    "\n",
    "    # system message\n",
    "    messages.append({'role': 'system', 'content': \"Classify each tweet in the batch as 0 (negative), 1 (neutral), or 2 (positive).\"})\n",
    "\n",
    "    # user message\n",
    "    messages.append({'role': 'user', 'content': \", \".join([f\"<TWEET>{[split.iat[j,0]]}</TWEET>\" for j in range(i_s, i_e)])})\n",
    "\n",
    "    if include_assistant:\n",
    "        # assistant message\n",
    "        messages.append({'role': 'assistant', 'content': \", \".join([f\"{split.iat[j,1]}\" for j in range(i_s, i_e)])})\n",
    "\n",
    "    return messages\n",
    "\n",
    "def calcAccuracy(df):\n",
    "    acc = 0\n",
    "    N = df.shape[0]\n",
    "    for i in range(df.shape[0]):\n",
    "        acc += 1 / N if df.at[i,'label'] == df.at[i,'prediction'] else 0\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make training data for finetuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# same dir as the kaggle data\n",
    "train_path = \"../data/fifa-tweet-sentiments/fifa_world_cup_2022_train_prompts.jsonl\"\n",
    "out = {}\n",
    "N = 80\n",
    "n_batch = 10\n",
    "bs = N // n_batch\n",
    "\n",
    "makeFinetuneData(train_split, train_path, N, n_batch, bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=\"<YOUR_OPENAI_API_KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-KmXUOHSN0mI9lb9oH9VoAE0N', bytes=17176, created_at=1703260768, filename='fifa_world_cup_2022_train_prompts.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload the training file\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "file_obj = client.files.create(\n",
    "  file=open(train_path, \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-XOrIG6yeh64kuKAxrpSAAkXW', created_at=1703260988, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-z274jjuiMMCtIYX9lKyIFDD8', result_files=[], status='validating_files', trained_tokens=None, training_file='file-KmXUOHSN0mI9lb9oH9VoAE0N', validation_file=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# kick-off a training job\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "client.fine_tuning.jobs.create(\n",
    "  training_file=file_obj.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJob](data=[FineTuningJob(id='ftjob-XOrIG6yeh64kuKAxrpSAAkXW', created_at=1703260988, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-z274jjuiMMCtIYX9lKyIFDD8', result_files=[], status='running', trained_tokens=None, training_file='file-KmXUOHSN0mI9lb9oH9VoAE0N', validation_file=None)], object='list', has_more=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List your current fine-tuning jobs\n",
    "jobs = client.fine_tuning.jobs.list(limit=10)\n",
    "jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-XOrIG6yeh64kuKAxrpSAAkXW', created_at=1703260988, error=None, fine_tuned_model='ft:gpt-3.5-turbo-0613:personal::8YcO68pw', finished_at=1703261405, hyperparameters=Hyperparameters(n_epochs=10, batch_size=1, learning_rate_multiplier=2), model='gpt-3.5-turbo-0613', object='fine_tuning.job', organization_id='org-z274jjuiMMCtIYX9lKyIFDD8', result_files=['file-5OzY6g0bAbPsE5GXWrHqCqTk'], status='succeeded', trained_tokens=55120, training_file='file-KmXUOHSN0mI9lb9oH9VoAE0N', validation_file=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of your fine_tuning job \n",
    "state = client.fine_tuning.jobs.retrieve(jobs.data[0].id)\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model name\n",
    "ft_model_name = state.fine_tuned_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the fine-tuned model available, we now call this model on a few prompts from the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:06<00:00,  1.57it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "batch_size = 8\n",
    "N = 10\n",
    "\n",
    "def callSentimentClfLllm(client, split, N, bs, model_name):\n",
    "\n",
    "    for i in trange(N):\n",
    "        messages = messagesFromSplit(split, i*bs, (i+1)*bs, include_assistant=False)\n",
    "\n",
    "        # print(prompts)\n",
    "        response = client.chat.completions.create(\n",
    "            model = model_name,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        for j, val in enumerate(response.choices[0].message.content.split(\", \")):\n",
    "            row = split.iloc[i*bs+j,:]\n",
    "            df_gpt = pd.concat([pd.DataFrame([[int(val),\n",
    "                                            row['label'],\n",
    "                                            row['text']]], columns=df_gpt.columns), df_gpt], ignore_index=True)\n",
    "    \n",
    "    return df_gpt\n",
    "\n",
    "df_gpt = callSentimentClfLllm(client, test_split, N, batch_size, ft_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6999999999999995\n"
     ]
    }
   ],
   "source": [
    "calcAccuracy(df_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this small sample from the test split, we've achieved about 70% accuracy. Let's see the performance on the larger test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 844/844 [08:52<00:00,  1.58it/s]\n"
     ]
    }
   ],
   "source": [
    "N = test_split.shape[0] // batch_size\n",
    "df_gpt = callSentimentClfLllm(client, test_split, N, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7270170244263887"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calcAccuracy(df_gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So finetuning has helped improve the GPT-3 based classifier to about 72.7% test accuracy. This is still not quite at the level of the huggingface classifier (83.9% test accuracy), and we could potentially iterate over our finetuning/prompting process to improve the LLM's accuracy. This could quickly get expensive, so we'll save that as an exercise for another time!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
